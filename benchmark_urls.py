BENCHMARK_DATASET_URLS = {
    # CRUXEval
    "CRUXEval-input": "https://crux-eval.github.io/",
    "CRUXEval-output": "https://crux-eval.github.io/",
    "CRUXEval-input-T0.2": "https://crux-eval.github.io/",
    "CRUXEval-input-T0.8": "https://crux-eval.github.io/",
    "CRUXEval-output-T0.2": "https://crux-eval.github.io/",
    "CRUXEval-output-T0.8": "https://crux-eval.github.io/",
    # EvalPlus
    "humaneval": "https://huggingface.co/datasets/openai/openai_humaneval",
    "humaneval+": "https://huggingface.co/datasets/evalplus/humanevalplus",
    "mbpp": "https://huggingface.co/datasets/google-research-datasets/mbpp",
    "mbpp+": "https://huggingface.co/datasets/evalplus/mbppplus",
    # LiveCodeBench
    "lcb_codegen_v5": "https://livecodebench.github.io/",
    "lcb_codegen_v6": "https://livecodebench.github.io/",
    "lcb_codegen_v6_080124": "https://livecodebench.github.io/",
    # DS-1000
    "DS1000": "https://ds1000-code-gen.github.io/",
    # SWE-bench
    "swebench-lite": "https://github.com/SWE-bench/experiments/tree/main/evaluation/lite",
    "swebench-verified": "https://github.com/SWE-bench/experiments/tree/main/evaluation/verified",
    "swebench-test": "https://github.com/SWE-bench/experiments/tree/main/evaluation/test",
    "swebench-bash-only": "https://github.com/SWE-bench/experiments/tree/main/evaluation/bash-only",
    "swebench-multimodal": "https://github.com/SWE-bench/experiments/tree/main/evaluation/multimodal",
    # Terminal Bench
    "terminal-bench-1.0": "https://github.com/laude-institute/terminal-bench-leaderboard/tree/main/results/terminal-bench-core%400.1.1",
    "terminal-bench-2.0": "https://huggingface.co/datasets/alexgshaw/terminal-bench-2-leaderboard/tree/main/submissions/terminal-bench/2.0",
    # SAFIM
    "safim": "https://huggingface.co/datasets/gonglinyuan/safim",
    # Reasoning / knowledge
    "arc_challenge": "https://huggingface.co/datasets/allenai/ai2_arc",
    "hellaswag": "https://huggingface.co/datasets/Rowan/hellaswag",
    "mmlu": "https://huggingface.co/datasets/cais/mmlu",
    "piqa": "https://huggingface.co/datasets/ybisk/piqa",
    "siqa": "https://huggingface.co/datasets/allenai/social_i_qa",
    "nq": "https://huggingface.co/datasets/google-research-datasets/natural_questions",
    "tqa": "https://huggingface.co/datasets/trivia_qa",
    "gsm8k": "https://huggingface.co/datasets/openai/gsm8k",
    "agi_english": "https://huggingface.co/datasets/baber/agieval",
}
